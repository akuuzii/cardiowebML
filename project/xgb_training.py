from project.utils import load_data
from skopt import forest_minimize
from sklearn.model_selection import cross_val_score
from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix, plot_roc_curve, f1_score

import xgboost as xgb
import numpy as np




data_dir = r'data/data_new_models.xlsx'

datasets = [
    'blanco_cac',
    'blanco',
    'non_blanco'
]


x_train, y_train, x_test, y_test, key_train, key_test = load_data(data_dir, datasets[1])



def tune_xgbc(params):
# Implementation learned on a lesson of Mario Filho (Kagle Grandmaster) for parametes optmization.
# Link to the video: https://www.youtube.com/watch?v=WhnkeasZNHI

    """Function to be passed as scikit-optimize minimizer/maximizer input

    Parameters:
    Tuples with information about the range that the optimizer should use for that parameter,
    as well as the behaviour that it should follow in that range.

    Returns:
    float: the metric that should be minimized. If the objective is maximization, then the negative
    of the desired metric must be returned. In this case, the negative AUC average generated by CV is returned.
    """


    #Hyperparameters to be optimized
    print(params)
    learning_rate = params[0]
    n_estimators = params[1]
    max_depth = params[2]
    min_child_weight = params[3]
    gamma = params[4]
    subsample = params[5]
    colsample_bytree = params[6]
    scale_pos_weight = params[7]


    #Model to be optimized
    mdl = xgb.XGBClassifier(objective = 'binary:logistic',
                            learning_rate = learning_rate,
                            n_estimators = n_estimators,
                            max_depth = max_depth,
                            min_child_weight = min_child_weight,
                            gamma = gamma,
                            subsample = subsample,
                            colsample_bytree = colsample_bytree,
                            scale_pos_weight = scale_pos_weight, seed = 42)


    #Cross-Validation in order to avoid overfitting
    f1 = cross_val_score(mdl,x_train,y_train, cv =10, scoring = 'f1')

    print(f1.mean())
    # as the function is minimization (forest_minimize), we need to use the negative of the desired metric (AUC)
    return -f1.mean()

dimensions = [(1e-3, 1e-1, 'log-uniform'), # learning rate
          (200, 1000), # n_estimators
          (1, 5), # max_depth
          (1, 6.), # min_child_weight
          (0, 0.3), # gamma
          (0.5, 1.), # subsample
          (0.5, 1.),# colsample_bytree
         (1,9)] #scale_pos_weight

result = forest_minimize(tune_xgbc, dimensions, random_state = 42, n_random_starts = 20, n_calls  = 100, verbose = 0)

check = result.x

cardiacXGB = xgb.XGBClassifier(objective='binary:logistic', verbosity=0, learning_rate = check[0],
n_estimators = check[1],
max_depth =check[2],
min_child_weight = check[3],
gamma = check[4],
subsample = check[5],
colsample_bytree = check[6],
scale_pos_weight = check[7],reg_lambda =5)


def f1_eval(y_pred, dtrain):
    y_true = dtrain.get_label()
    err = 1-f1_score(y_true, np.round(y_pred))
    return 'f1_err', err


cardiacXGB.fit(x_train, y_train,eval_metric=f1_eval)


# Model Training performance
y_pred = np.round(cardiacXGB.predict(x_train)) # ,output_margin=True)
y_scores = cardiacXGB.predict_proba(x_train)[:, 1]

print(confusion_matrix(y_train, y_pred))
print(classification_report(y_train, y_pred))

fpr, tpr, auc_thresholds = roc_curve(y_train, y_scores)
print(auc(fpr, tpr))  # AUC of ROC
plot_roc_curve(fpr, tpr, 'recall_optimized')


# Model Training performance
y_pred = np.round(cardiacXGB.predict(x_test)) # ,output_margin=True)
y_scores = cardiacXGB.predict_proba(x_test)[:, 1]

print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

fpr, tpr, auc_thresholds = roc_curve(y_test, y_scores)
print(auc(fpr, tpr))  # AUC of ROC
plot_roc_curve(fpr, tpr, 'recall_optimized')


import matplotlib.pyplot as plt

plt.plot(fpr,tpr)